"""Planning Handler - ê°œë°œ ê³„íš ìˆ˜ë¦½ ì²˜ë¦¬.

ì´ í•¸ë“¤ëŸ¬ëŠ” ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ê³  ê°œë°œ ê³„íšì„ ìˆ˜ë¦½í•©ë‹ˆë‹¤.
ë³µì¡í•œ ì‘ì—…ì˜ ê²½ìš° ê³„íšì„ íŒŒì¼ë¡œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Phase 5: êµ¬ì¡°í™”ëœ ê³„íš ìƒì„± ë° ì‚¬ìš©ì ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš° ì§€ì›
"""
import json
import logging
import re
import uuid
import aiofiles
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, AsyncGenerator, List

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

from app.core.config import settings
from app.agent.handlers.base import BaseHandler, HandlerResult, StreamUpdate
from app.agent.langgraph.schemas.plan import ExecutionPlan, PlanStep
from shared.utils.token_utils import estimate_tokens, create_token_usage
from shared.utils.language_utils import detect_language, get_language_instruction

logger = logging.getLogger(__name__)


# Structured Plan Generation Prompt (Phase 5)
STRUCTURED_PLAN_PROMPT = """You are an expert software architect creating a detailed execution plan.

Analyze the user's request and create a structured plan with specific, actionable steps.

IMPORTANT: Output your plan in the following JSON format ONLY (no markdown, no additional text):

{{
    "summary": "Brief summary of what will be built",
    "steps": [
        {{
            "step": 1,
            "action": "create_file",
            "target": "src/calculator.py",
            "description": "Create main calculator module with basic arithmetic operations",
            "requires_approval": false,
            "estimated_complexity": "low",
            "dependencies": []
        }},
        {{
            "step": 2,
            "action": "create_file",
            "target": "tests/test_calculator.py",
            "description": "Create unit tests for calculator module",
            "requires_approval": false,
            "estimated_complexity": "low",
            "dependencies": [1]
        }}
    ],
    "estimated_files": ["src/calculator.py", "tests/test_calculator.py"],
    "risks": ["None identified for this simple task"]
}}

Available actions:
- create_file: Create a new file
- modify_file: Modify an existing file
- delete_file: Delete a file
- run_tests: Run test suite
- run_lint: Run linter
- install_deps: Install dependencies
- refactor: Refactor existing code
- review_code: Review code for issues

Complexity levels: low, medium, high

Set requires_approval=true for:
- Deleting files
- Modifying core/critical files
- High complexity changes
- Security-sensitive operations

User Request:
{user_request}

Context:
{context}

Generate the structured plan JSON:"""


def _get_planning_system_prompt(model_type: str, user_message: str = "", project_name: str = "") -> str:
    """ëª¨ë¸ íƒ€ì…ê³¼ ì‚¬ìš©ì ì–¸ì–´ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜

    Args:
        model_type: LLM ëª¨ë¸ íƒ€ì…
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€ (ì–¸ì–´ ê°ì§€ìš©)
        project_name: í”„ë¡œì íŠ¸ ì´ë¦„ (ì»¨í…ìŠ¤íŠ¸ìš©)

    Returns:
        ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
    """
    # ì–¸ì–´ ê°ì§€ ë° ì§€ì‹œì–´ ìƒì„±
    language_instruction = ""
    if user_message:
        language = detect_language(user_message)
        language_instruction = get_language_instruction(language)

    # í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
    project_context = ""
    if project_name:
        project_context = f"""
[PROJECT CONTEXT]
You are working on a project named "{project_name}".
All generated files and code should be organized within this project's directory structure.
Use "{project_name}" as the root directory for file paths when suggesting file organization.
[/PROJECT CONTEXT]

"""

    base_prompt = """You are an expert software architect and development planner.

Your task is to analyze user requests and create detailed, actionable development plans.

When creating a plan:
1. Break down the task into clear, manageable steps
2. Identify potential challenges and solutions
3. Consider best practices and design patterns
4. Suggest appropriate technologies and libraries
5. Estimate relative complexity of each component

Output format:
- Use clear markdown formatting
- Number your steps
- Include code structure suggestions where helpful
- Provide rationale for key decisions"""

    if model_type == "deepseek":
        return f"""{language_instruction}{project_context}<think>
Before responding, analyze:
1. What is the user trying to build?
2. What are the key components needed?
3. What challenges might arise?
4. What's the best architecture?
</think>

{base_prompt}"""
    else:
        return language_instruction + project_context + base_prompt


class PlanningHandler(BaseHandler):
    """ê°œë°œ ê³„íš ìˆ˜ë¦½ í•¸ë“¤ëŸ¬

    ì‚¬ìš©ì ìš”ì²­ì„ ë¶„ì„í•˜ê³  ê°œë°œ ê³„íšì„ ìƒì„±í•©ë‹ˆë‹¤.
    ë³µì¡í•œ ì‘ì—…ì€ ê³„íš íŒŒì¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.
    """

    def __init__(self):
        """PlanningHandler ì´ˆê¸°í™”"""
        super().__init__()

        # Reasoning LLM ì‚¬ìš© (ë” ê¹Šì€ ë¶„ì„)
        self.llm = ChatOpenAI(
            base_url=settings.vllm_reasoning_endpoint,
            model=settings.reasoning_model,
            temperature=0.7,
            max_tokens=4096,
            api_key="not-needed",
        )

        self.model_type = settings.get_reasoning_model_type
        self.logger.info(f"PlanningHandler initialized (model_type: {self.model_type})")

    async def execute(
        self,
        user_message: str,
        analysis: Dict[str, Any],
        context: Any
    ) -> HandlerResult:
        """ê³„íš ìˆ˜ë¦½ ì‹¤í–‰

        Args:
            user_message: ì‚¬ìš©ì ìš”ì²­
            analysis: Supervisor ë¶„ì„ ê²°ê³¼
            context: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸

        Returns:
            HandlerResult: ì²˜ë¦¬ ê²°ê³¼ (ê³„íš + ì˜µì…˜ìœ¼ë¡œ íŒŒì¼ ì €ì¥)
        """
        try:
            # í”„ë¡œì íŠ¸ ì´ë¦„ ì¶”ì¶œ (ë² ì´ìŠ¤ í´ë˜ìŠ¤ ë©”ì„œë“œ ì‚¬ìš©)
            project_name = self._get_project_name(context)

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì–¸ì–´ ê°ì§€ ë° í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì ìš©)
            system_prompt = _get_planning_system_prompt(self.model_type, user_message, project_name)

            # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
            context_info = self._build_context_info(analysis, context)

            # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            user_prompt = f"""## ìš”ì²­ ë¶„ì„
{context_info}

## ì‚¬ìš©ì ìš”ì²­
{user_message}

## ì‘ì—…
ìœ„ ìš”ì²­ì— ëŒ€í•œ ìƒì„¸í•œ ê°œë°œ ê³„íšì„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

            # LLM í˜¸ì¶œ
            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]

            self.logger.info(f"Planning: {user_message[:50]}...")
            response = await self.llm.ainvoke(messages)

            # ì‘ë‹µ ì •ë¦¬
            plan_content = self._strip_think_tags(response.content)

            # ì‚¬ìš©ì ì¹œí™”ì  ì‘ë‹µ ìƒì„±
            user_response = self._format_user_response(plan_content, analysis)

            # ë³µì¡í•œ ì‘ì—…ì€ íŒŒì¼ë¡œ ì €ì¥
            plan_file = None
            complexity = analysis.get("complexity", "simple")

            if complexity in ["complex", "critical"] and context and hasattr(context, 'workspace'):
                workspace = context.workspace
                if workspace:
                    plan_file = await self._save_plan_file(plan_content, workspace, user_message)

            # ë©”íƒ€ë°ì´í„°
            metadata = {
                "complexity": complexity,
                "plan_saved": plan_file is not None
            }

            self.logger.info(f"Planning completed (saved: {plan_file is not None})")

            return HandlerResult(
                content=user_response,
                artifacts=[],
                plan_file=plan_file,
                metadata=metadata,
                success=True
            )

        except Exception as e:
            return self._create_error_result(e)

    async def execute_stream(
        self,
        user_message: str,
        analysis: Dict[str, Any],
        context: Any
    ) -> AsyncGenerator[StreamUpdate, None]:
        """ìŠ¤íŠ¸ë¦¬ë° ê³„íš ìˆ˜ë¦½

        Args:
            user_message: ì‚¬ìš©ì ìš”ì²­
            analysis: Supervisor ë¶„ì„ ê²°ê³¼
            context: ëŒ€í™” ì»¨í…ìŠ¤íŠ¸

        Yields:
            StreamUpdate: ìŠ¤íŠ¸ë¦¬ë° ì—…ë°ì´íŠ¸
        """
        yield self._create_progress_update(
            message="ìš”ì²­ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
            streaming_content="## ë¶„ì„ ì‹œì‘\n- ìš”ì²­ ë‚´ìš© íŒŒì•… ì¤‘...\n- ë³µì¡ë„ í‰ê°€ ì¤‘..."
        )

        try:
            # í”„ë¡œì íŠ¸ ì´ë¦„ ì¶”ì¶œ (ë² ì´ìŠ¤ í´ë˜ìŠ¤ ë©”ì„œë“œ ì‚¬ìš©)
            project_name = self._get_project_name(context)

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì–¸ì–´ ê°ì§€ ë° í”„ë¡œì íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì ìš©)
            system_prompt = _get_planning_system_prompt(self.model_type, user_message, project_name)
            context_info = self._build_context_info(analysis, context)

            user_prompt = f"""## ìš”ì²­ ë¶„ì„
{context_info}

## ì‚¬ìš©ì ìš”ì²­
{user_message}

## ì‘ì—…
ìœ„ ìš”ì²­ì— ëŒ€í•œ ìƒì„¸í•œ ê°œë°œ ê³„íšì„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=user_prompt)
            ]

            # ìŠ¤íŠ¸ë¦¬ë° LLM í˜¸ì¶œ
            plan_content = ""
            last_update_len = 0
            async for chunk in self.llm.astream(messages):
                if chunk.content:
                    plan_content += chunk.content

                    # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ (100ìë§ˆë‹¤ ë˜ëŠ” ì˜ë¯¸ìˆëŠ” ë³€í™”ê°€ ìˆì„ ë•Œ)
                    if len(plan_content) - last_update_len >= 100:
                        last_update_len = len(plan_content)
                        # think íƒœê·¸ ì œê±°í•œ ë¯¸ë¦¬ë³´ê¸° ìƒì„±
                        preview = self._strip_think_tags(plan_content)
                        # ìµœê·¼ 500ìë§Œ streaming_contentë¡œ ì „ë‹¬
                        preview_content = preview[-500:] if len(preview) > 500 else preview

                        # Real-time token estimation
                        current_token_usage = {
                            "prompt_tokens": estimate_tokens(f"{system_prompt}\n{user_prompt}"),
                            "completion_tokens": estimate_tokens(plan_content),
                            "total_tokens": estimate_tokens(f"{system_prompt}\n{user_prompt}") + estimate_tokens(plan_content)
                        }

                        yield StreamUpdate(
                            agent="PlanningHandler",
                            update_type="streaming",
                            status="running",
                            message=f"ê³„íš ì‘ì„± ì¤‘... ({len(plan_content)} ì)",
                            streaming_content=preview_content,
                            data={"token_usage": current_token_usage}
                        )

            # ì •ë¦¬ ë° ì €ì¥
            plan_content = self._strip_think_tags(plan_content)
            user_response = self._format_user_response(plan_content, analysis)

            plan_file = None
            complexity = analysis.get("complexity", "simple")

            if complexity in ["complex", "critical"] and context and hasattr(context, 'workspace'):
                workspace = context.workspace
                if workspace:
                    plan_file = await self._save_plan_file(plan_content, workspace, user_message)

            # Calculate token usage
            full_prompt = f"{system_prompt}\n{user_prompt}"
            token_usage = create_token_usage(full_prompt, plan_content)

            yield StreamUpdate(
                agent="PlanningHandler",
                update_type="completed",
                status="completed",
                message=user_response[:200],
                streaming_content=plan_content,
                data={
                    "plan_file": plan_file,
                    "full_content": user_response,
                    "token_usage": token_usage
                }
            )

        except Exception as e:
            yield self._create_error_update(e)

    def _build_context_info(self, analysis: Dict[str, Any], context: Any) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ë¬¸ìì—´ ìƒì„±"""
        parts = []

        # Supervisor ë¶„ì„ ì •ë³´
        if analysis:
            complexity = analysis.get("complexity", "unknown")
            task_type = analysis.get("task_type", "unknown")
            parts.append(f"- ë³µì¡ë„: {complexity}")
            parts.append(f"- ì‘ì—… ìœ í˜•: {task_type}")

        # ì´ì „ ëŒ€í™” ìš”ì•½ (ìˆëŠ” ê²½ìš°)
        if context and hasattr(context, 'get_conversation_summary'):
            summary = context.get_conversation_summary()
            if summary:
                parts.append(f"- ì´ì „ ëŒ€í™”: {summary[:200]}")

        # ê¸°ì¡´ ì•„í‹°íŒ©íŠ¸ (ìˆëŠ” ê²½ìš°)
        if context and hasattr(context, 'get_artifact_summary'):
            artifacts = context.get_artifact_summary()
            if artifacts and artifacts != "ìƒì„±ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.":
                parts.append(f"- ê¸°ì¡´ íŒŒì¼:\n{artifacts}")

        return "\n".join(parts) if parts else "ìƒˆ ì‘ì—…ì…ë‹ˆë‹¤."

    def _format_user_response(self, plan_content: str, analysis: Dict[str, Any]) -> str:
        """ì‚¬ìš©ì ì¹œí™”ì  ì‘ë‹µ ìƒì„±

        Args:
            plan_content: ìƒì„±ëœ ê³„íš ë‚´ìš©
            analysis: ë¶„ì„ ê²°ê³¼

        Returns:
            str: í¬ë§·ëœ ì‘ë‹µ
        """
        complexity = analysis.get("complexity", "simple")

        header = "## ê°œë°œ ê³„íš\n\n"
        footer = "\n\n---\n"

        if complexity in ["complex", "critical"]:
            footer += "ì´ ê³„íšì´ ì ì ˆí•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”. ì§„í–‰í•˜ë ¤ë©´ 'ì½”ë“œ ìƒì„± ì‹œì‘'ì´ë¼ê³  ë§ì”€í•´ì£¼ì„¸ìš”."
        else:
            footer += "ê³„íšì„ í™•ì¸í•˜ê³ , ì½”ë“œ ìƒì„±ì„ ì›í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”."

        return header + plan_content + footer

    async def _save_plan_file(
        self,
        content: str,
        workspace: str,
        user_message: str
    ) -> Optional[str]:
        """ê³„íšì„ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ë¡œ ì €ì¥

        Args:
            content: ê³„íš ë‚´ìš©
            workspace: ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê²½ë¡œ
            user_message: ì›ë³¸ ìš”ì²­ (íŒŒì¼ëª… ìƒì„±ìš©)

        Returns:
            Optional[str]: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
        """
        try:
            # íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

            # ìš”ì²­ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (íŒŒì¼ëª…ìš©)
            keywords = re.findall(r'[ê°€-í£a-zA-Z]+', user_message)[:3]
            keyword_part = "_".join(keywords) if keywords else "plan"
            keyword_part = keyword_part[:30]  # ê¸¸ì´ ì œí•œ

            filename = f"PLAN_{keyword_part}_{timestamp}.md"

            # ì €ì¥ ê²½ë¡œ
            plans_dir = Path(workspace) / ".plans"
            plans_dir.mkdir(parents=True, exist_ok=True)

            filepath = plans_dir / filename

            # íŒŒì¼ ë‚´ìš© êµ¬ì„±
            file_content = f"""# Development Plan

**Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Request**: {user_message[:200]}

---

{content}

---
*This plan was automatically generated. Review and modify as needed.*
"""

            # ì €ì¥
            async with aiofiles.open(filepath, 'w', encoding='utf-8') as f:
                await f.write(file_content)

            self.logger.info(f"Plan saved: {filepath}")
            return str(filepath)

        except Exception as e:
            self.logger.error(f"Failed to save plan file: {e}")
            return None

    async def generate_structured_plan(
        self,
        user_message: str,
        session_id: str,
        analysis: Dict[str, Any],
        context: Any = None
    ) -> ExecutionPlan:
        """Generate a structured execution plan (Phase 5)

        Creates a detailed, step-by-step execution plan that can be
        reviewed and approved by the user before execution.

        Args:
            user_message: User's request
            session_id: Session identifier
            analysis: Supervisor analysis result
            context: Optional conversation context

        Returns:
            ExecutionPlan: Structured plan for user approval
        """
        try:
            self.logger.info(f"Generating structured plan for: {user_message[:50]}...")

            # Build context info
            context_info = self._build_context_info(analysis, context)

            # Format prompt
            prompt = STRUCTURED_PLAN_PROMPT.format(
                user_request=user_message,
                context=context_info
            )

            # System prompt for structured output
            system_prompt = """You are a software architecture expert.
Generate ONLY valid JSON output. No markdown, no explanations, just the JSON object.
Ensure the JSON is properly formatted and parseable."""

            if self.model_type == "deepseek":
                system_prompt = f"""<think>
Analyze the request and determine:
1. What files need to be created or modified
2. What is the logical order of operations
3. Which steps might need user approval
4. What are the potential risks
</think>

{system_prompt}"""

            messages = [
                SystemMessage(content=system_prompt),
                HumanMessage(content=prompt)
            ]

            # Call LLM
            response = await self.llm.ainvoke(messages)
            response_text = self._strip_think_tags(response.content)

            # Parse JSON response
            plan_data = self._parse_plan_json(response_text)

            # Create PlanStep objects
            steps = []
            for step_data in plan_data.get("steps", []):
                steps.append(PlanStep(
                    step=step_data.get("step", len(steps) + 1),
                    action=step_data.get("action", "custom"),
                    target=step_data.get("target", ""),
                    description=step_data.get("description", ""),
                    requires_approval=step_data.get("requires_approval", False),
                    estimated_complexity=step_data.get("estimated_complexity", "low"),
                    dependencies=step_data.get("dependencies", []),
                ))

            # Create ExecutionPlan
            plan = ExecutionPlan.create(
                session_id=session_id,
                user_request=user_message,
                steps=steps,
                estimated_files=plan_data.get("estimated_files", []),
                risks=plan_data.get("risks", [])
            )

            self.logger.info(f"Structured plan created: {plan.plan_id} with {len(steps)} steps")
            return plan

        except Exception as e:
            self.logger.error(f"Failed to generate structured plan: {e}")
            # Return a minimal plan on error
            return ExecutionPlan.create(
                session_id=session_id,
                user_request=user_message,
                steps=[PlanStep(
                    step=1,
                    action="custom",
                    target="",
                    description=f"Execute request: {user_message[:100]}",
                    requires_approval=True,
                    estimated_complexity="medium",
                )],
                estimated_files=[],
                risks=[f"Plan generation failed: {str(e)}"]
            )

    def _parse_plan_json(self, response_text: str) -> Dict[str, Any]:
        """Parse JSON from LLM response

        Handles various edge cases like markdown code blocks,
        extra text before/after JSON, etc.

        Args:
            response_text: Raw LLM response

        Returns:
            Parsed JSON dictionary
        """
        # Try direct JSON parse first
        try:
            return json.loads(response_text.strip())
        except json.JSONDecodeError:
            pass

        # Try extracting JSON from markdown code block
        json_match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', response_text)
        if json_match:
            try:
                return json.loads(json_match.group(1))
            except json.JSONDecodeError:
                pass

        # Try finding JSON object in text
        brace_match = re.search(r'\{[\s\S]*\}', response_text)
        if brace_match:
            try:
                return json.loads(brace_match.group(0))
            except json.JSONDecodeError:
                pass

        # Return empty plan structure
        self.logger.warning("Failed to parse plan JSON, returning empty structure")
        return {
            "summary": "Failed to parse plan",
            "steps": [],
            "estimated_files": [],
            "risks": ["Plan parsing failed"]
        }

    async def generate_structured_plan_stream(
        self,
        user_message: str,
        session_id: str,
        analysis: Dict[str, Any],
        context: Any = None
    ) -> AsyncGenerator[StreamUpdate, None]:
        """Generate structured plan with streaming updates

        Args:
            user_message: User's request
            session_id: Session identifier
            analysis: Supervisor analysis result
            context: Optional conversation context

        Yields:
            StreamUpdate: Progress updates during plan generation
        """
        yield self._create_progress_update(
            message="êµ¬ì¡°í™”ëœ ì‹¤í–‰ ê³„íšì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
            streaming_content="## ê³„íš ìƒì„± ì¤‘\n- ìš”ì²­ ë¶„ì„ ì¤‘...\n- ë‹¨ê³„ë³„ ì‘ì—… êµ¬ì„± ì¤‘..."
        )

        try:
            # Generate the plan
            plan = await self.generate_structured_plan(
                user_message=user_message,
                session_id=session_id,
                analysis=analysis,
                context=context
            )

            # Format plan for display
            plan_display = self._format_plan_for_display(plan)

            yield StreamUpdate(
                agent="PlanningHandler",
                update_type="plan_generated",
                status="awaiting_approval",
                message=f"ì‹¤í–‰ ê³„íšì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. {plan.total_steps}ê°œ ë‹¨ê³„",
                streaming_content=plan_display,
                data={
                    "plan": plan.to_dict(),
                    "requires_approval": True,
                }
            )

        except Exception as e:
            yield self._create_error_update(e)

    def _format_plan_for_display(self, plan: ExecutionPlan) -> str:
        """Format ExecutionPlan for user-friendly display

        Args:
            plan: ExecutionPlan object

        Returns:
            Formatted markdown string
        """
        lines = [
            "## ì‹¤í–‰ ê³„íš",
            "",
            f"**Plan ID**: `{plan.plan_id}`",
            f"**ì´ ë‹¨ê³„**: {plan.total_steps}ê°œ",
            "",
            "### ë‹¨ê³„ë³„ ì‘ì—…",
            ""
        ]

        for step in plan.steps:
            approval_badge = " [ìŠ¹ì¸ í•„ìš”]" if step.requires_approval else ""
            complexity_icon = {"low": "ğŸŸ¢", "medium": "ğŸŸ¡", "high": "ğŸ”´"}.get(
                step.estimated_complexity, "âšª"
            )

            lines.append(f"**{step.step}. {step.description}**{approval_badge}")
            lines.append(f"   - ì‘ì—…: `{step.action}`")
            lines.append(f"   - ëŒ€ìƒ: `{step.target}`")
            lines.append(f"   - ë³µì¡ë„: {complexity_icon} {step.estimated_complexity}")
            if step.dependencies:
                lines.append(f"   - ì„ í–‰ ë‹¨ê³„: {step.dependencies}")
            lines.append("")

        if plan.estimated_files:
            lines.append("### ì˜ˆìƒ íŒŒì¼")
            for f in plan.estimated_files:
                lines.append(f"- `{f}`")
            lines.append("")

        if plan.risks:
            lines.append("### ìœ„í—˜ ìš”ì†Œ")
            for risk in plan.risks:
                lines.append(f"- {risk}")
            lines.append("")

        lines.extend([
            "---",
            "",
            "ì´ ê³„íšì„ **ìŠ¹ì¸**í•˜ì‹œë ¤ë©´ 'ìŠ¹ì¸' ë˜ëŠ” 'approve'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.",
            "**ìˆ˜ì •**ì´ í•„ìš”í•˜ì‹œë©´ ìˆ˜ì • ë‚´ìš©ì„ ë§ì”€í•´ì£¼ì„¸ìš”.",
            "**ê±°ë¶€**í•˜ì‹œë ¤ë©´ 'ê±°ë¶€' ë˜ëŠ” 'reject'ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
        ])

        return "\n".join(lines)
