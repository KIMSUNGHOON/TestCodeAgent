# ============================================
# AI Code Assistance Application Configuration
# ============================================
# Copy this file to .env and modify as needed
# cp .env.example .env

# =========================
# LLM Configuration
# =========================

# Primary LLM endpoint (used as default for all tasks)
# IMPORTANT: Use localhost or 127.0.0.1, NOT 0.0.0.0 for client connections
LLM_ENDPOINT=http://localhost:8001/v1
LLM_MODEL=deepseek-ai/DeepSeek-R1

# Model type for prompt selection
# Options: deepseek, qwen, gpt, claude, generic
MODEL_TYPE=deepseek

# Optional: Task-specific endpoints (override LLM_ENDPOINT if set)
VLLM_REASONING_ENDPOINT=http://localhost:8001/v1
VLLM_CODING_ENDPOINT=http://localhost:8002/v1

# Optional: Task-specific models (override LLM_MODEL if set)
REASONING_MODEL=deepseek-ai/DeepSeek-R1
CODING_MODEL=Qwen/Qwen3-8B-Coder

# =========================
# Agent Framework Selection
# =========================
# Options: microsoft, langchain, deepagent
# - microsoft: Original Microsoft Agent Framework (default)
# - langchain: LangChain/LangGraph based agents
# - deepagent: DeepAgents with advanced capabilities
AGENT_FRAMEWORK=microsoft

# =========================
# API Server Configuration
# =========================
# Note: 0.0.0.0 is correct here for SERVER binding (accepts all interfaces)
API_HOST=0.0.0.0
API_PORT=8000
API_RELOAD=true

# =========================
# CORS Configuration
# =========================
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# =========================
# Logging
# =========================
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO
